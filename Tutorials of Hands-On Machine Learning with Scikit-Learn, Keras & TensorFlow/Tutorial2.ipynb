{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❗️ **本教程知识体系来源于**\n",
    "**Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow, 2nd edition**\n",
    "**作者为Aurélien Géron**\n",
    "\n",
    "**知识产权归原作者所有，如有侵权请联系删除**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 动手做机器学习教程2 - 一个简易的机器学习项目（上）\n",
    ">在本节和下一节，我们会完整做完一个简单的机器学习项目，以此来说明做机器学习项目的大体流程。在本节，我们将进行有关数据的各种操作：数据的获得、可视化以及处理。\n",
    ">\n",
    ">数据来源：https://www.kaggle.com/spscientist/students-performance-in-exams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.在开始之前...\n",
    "### (1) 从哪里获得数据\n",
    "* 在实际工作中，我们自然会从工作上级、工作甲方、项目上一环节处拿到我们需要的数据；但平日练习时，我们可以从以下几个网站获取开放数据集：\n",
    ">[Kaggle数据集](https://www.kaggle.com/datasets)\n",
    ">\n",
    ">[加州大学尔湾分校机器学习数据集](http://archive.ics.uci.edu/ml/index.php)\n",
    ">\n",
    ">[数据堂](https://www.datatang.com)\n",
    ">\n",
    ">[阿里云天池数据集](https://tianchi.aliyun.com/dataset)\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "在本例中，我们从Kaggle获取了所需的数据：\n",
    "\n",
    "该数据集包括一些学生的**性别、种族、父母教育水平、午餐选择（以此表现经济实力）、是否参与考试复习课**，以及数学、阅读、写作**三项考试的分数**。\n",
    "</p></div>\n",
    "\n",
    "### (2) 确定你的位置\n",
    "* 数据管道(data pipeline)：真正的数据处理过程很像一条流水线，因此被称为数据管道。一般情况下，一个团队负责数据管道的一个环节，他们**拿到上一个环节处理好的数据，根据自己的目标进行处理，然后传给下一个环节**。这样既能方便每个团队进行工作，又能让整个系统易于监控。\n",
    "* 根据位置确定你的目标：我们要先明白我们所做的工作处在数据管道的什么位置，并根据位置制定我们的目标。\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "假设整个项目的数据管道如下所示：\n",
    "    \n",
    "原始数据的获取→数据的初步清洗和整理→根据需求创建模型→投入使用，进行回归预测\n",
    "    \n",
    "我们的位置是**根据需求创建模型环节**，我们需要了解父母背景、考试复习课等要素对学生成绩的影响，并建立模型。这样，我们便可以把模型交给下一个环节，让他们根据一个学生的个人情况来对其考试分数进行预测。</p></div>\n",
    "\n",
    "### (3) 确定你的系统\n",
    "* 根据我们的数据类型以及目标，我们需要确定使用哪种机器学习系统。我们应该使用监督学习、无监督学习还是强化学习？我们在做的是回归、分类还是其他的任务？我们应该使用批量学习还是在线学习？如果读者不甚清楚，可以回顾我们**第一篇教程第三节**的部分。\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "答案：\n",
    "\n",
    "由于我们的数据带有标签——每个学生的实际考试分数，因此我们应该使用监督学习。\n",
    "\n",
    "这个项目做的是监督学习中的回归任务，因为我们要利用学生的情况来对其进行预测。\n",
    "\n",
    "最后，因为我们的数据集仅是一个csv文档，且我们的项目不需要持续收集并快速更新数据，我们只需使用批量学习。</p></div>\n",
    "\n",
    "❗️ ❗️ ❗️ 为了方便，我们假定**三门课程的分数是独立的**，即每门课程的分数不会对另外两门的分数造成任何影响（实际上可能并不是这样）。这样我们便可以利用回归算法分别对每一门分数进行建模并测试，接下来我们仅对**数学**一门课的分数进行建模并测试，阅读、写作同数学，仅更改代码中的列名并从头运行，便可对阅读、写作的分数进行建模。\n",
    "\n",
    "**请切记我们的假设！**\n",
    "\n",
    "### (4) 确定性能度量\n",
    "* 在回归问题中，我们常使用两种性能度量(performance measurement)来考察模型：**均方根误差(RMSE)**和**平均绝对误差(MAE)**。\n",
    "\n",
    "* 令$\\pmb{x}^{(i)}$表示第i个数据除标签外的所有特征的值，它是一个列向量。\n",
    "  \n",
    "  令$y^{(i)}$表示第i个数据的标签的值。\n",
    "\n",
    "  假设我们共有**m个数据**，则可以用矩阵$\\pmb{X}$来代表我们数据集除标签外的所有特征的值：\n",
    "  \n",
    "  $$\\pmb{X} = \n",
    "  \\left(\n",
    "  \\begin{matrix}\n",
    "   (\\pmb{x}^{(1)})^{T}    \\\\\n",
    "   (\\pmb{x}^{(2)})^{T}    \\\\\n",
    "   \\vdots                 \\\\\n",
    "   (\\pmb{x}^{(m)})^{T}    \\\\\n",
    "  \\end{matrix}\n",
    "  \\right)\n",
    "  $$\n",
    "  其中T表示将列向量转置为行向量。\n",
    "  \n",
    "  $h(\\pmb{x})$代表我们系统的预测函数。我们输入一个列向量，函数会输出一个预测值$\\hat{y}$\n",
    "\n",
    "\n",
    "* 均方根误差（RMSE）：$$ RMSE(\\pmb{X},h) = \\sqrt{\\frac{1}{m} \\sum_{i=1}^{m} ({\\hat{y}^{(i)}-y^{(i)}})^{2}} = \\sqrt{\\frac{1}{m} \\sum_{i=1}^{m} ({h(\\pmb{x}^{(i)})-y^{(i)}})^{2}} $$\n",
    "\n",
    "\n",
    "* 平均绝对误差（MAE）:$$ MAE(\\pmb{X},h) = \\frac{1}{m} \\sum_{i=1}^{m} \\mid{\\hat{y}^{(i)}-y^{(i)}}\\mid = \\frac{1}{m} \\sum_{i=1}^{m} \\mid{h(\\pmb{x}^{(i)})-y^{(i)}}\\mid $$\n",
    "\n",
    "\n",
    "* 一般情况下，我们都可以使用均方根误差来作为我们的性能度量。若数据中**异常值太多**，则我们可以使用平均绝对误差。\n",
    "\n",
    "❗️ 注意：这两种性能度量在检测时，返回值越**低**表明模型拟合度越好。\n",
    "\n",
    "### (5) 沟通&复查\n",
    "* 我们马上就要开始了，在此之前，我们需要再次与数据管道的上一环节、下一环节进行沟通，让他们了解我们在(2)(3)(4)中所做的事。若他们没有任何问题，我们就可以开始了！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.开始！\n",
    "### (1) 建立工作空间\n",
    "* 我们所使用的工具是**Python 3.6与TensorFlow 2.0.0**。我们可以在[Openbayes](https://openbayes.com/)中新建算力容器，并选择**TensorFlow 2.0.0**，这样系统会自动生成Jupyter Notebook，我们便可以开始敲代码了。\n",
    "* 当然，我们也可以通过在电脑上安装Python和Jupyter Notebook来自己新建Notebook。您可以访问[Anaconda官网](https://www.anaconda.com/)来下载它们。\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "我们选择使用Openbayes来进行以下所有操作：先上传所需的数据集，再新建算力容器并打开Jupyter Notebook。\n",
    "</p></div>\n",
    "\n",
    "* 第一步：在Openbayes控制台点击①处（**新建数据集**），并在此②处对数据集的名称和③处对描述进行完善，类别**不做更改**（即选择“数据集”），最后点击④处创建数据集。\n",
    "\n",
    "<img src=\"Pictures/2新建数据集.jpg\" width = 80% height = 80% div align=center /> \n",
    "  \n",
    "  \n",
    "* 第二步：我们选择“上传数据”，并上传我们从Kaggle上下载的csv文件。\n",
    "  \n",
    "<img src=\"Pictures/2上传数据.jpg\" width = 80% height = 80% div align=center /> \n",
    "  \n",
    "\n",
    "* 第三步：在Openbayes控制台点击**新建算力容器**。\n",
    "\n",
    "<img src=\"Pictures/2新建算力容器.jpg\" width = 20% height = 20% div align=center /> \n",
    "\n",
    "\n",
    "* 第四步：对容器信息进行完善。\n",
    "\n",
    "<img src=\"Pictures/2容器名称.jpg\" width = 80% height = 80% div align=center /> \n",
    "    \n",
    "在①处填写容器名称→点击②处，选择我们刚创建的数据集，绑定的目录**不做更改**（即绑定至/input0）→点击③处的下拉箭头，选择**TensorFlow 2.0.0**→点击④创建容器\n",
    "  \n",
    "* 第五步：稍等片刻，等待**“打开Jupyter编辑器”**按钮出现后，点击该按钮。\n",
    "\n",
    "<img src=\"Pictures/2打开jupyter.jpg\" width = 80% height = 80% div align=center /> \n",
    "\n",
    "点击“Launcher”，并选择“Python3”\n",
    "    \n",
    "<img src=\"Pictures/2launcher.jpg\" width = 80% height = 80% div align=center />\n",
    "<img src=\"Pictures/2python.jpg\" width = 80% height = 80% div align=center />\n",
    "\n",
    "\n",
    "* 我们已经进入Notebook界面了。\n",
    "\n",
    "<img src=\"Pictures/2进入notebook.jpg\" width = 80% height = 80% div align=center />\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "我们使用Notebook来进行以下所有操作：\n",
    "</p></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) 读取数据\n",
    "我们利用Python的**pandas库**来将csv文件读至一个DataFrame中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('F:\\python\\Jupyter\\OpenBayes\\StudentsPerformance.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3) 大致了解数据\n",
    "我们先用DataFrame的**head()**方法看一下数据的前五行，以此来对数据有大概的了解："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>race/ethnicity</th>\n",
       "      <th>parental level of education</th>\n",
       "      <th>lunch</th>\n",
       "      <th>test preparation course</th>\n",
       "      <th>math score</th>\n",
       "      <th>reading score</th>\n",
       "      <th>writing score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>female</td>\n",
       "      <td>group B</td>\n",
       "      <td>bachelor's degree</td>\n",
       "      <td>standard</td>\n",
       "      <td>none</td>\n",
       "      <td>72</td>\n",
       "      <td>72</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>female</td>\n",
       "      <td>group C</td>\n",
       "      <td>some college</td>\n",
       "      <td>standard</td>\n",
       "      <td>completed</td>\n",
       "      <td>69</td>\n",
       "      <td>90</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>female</td>\n",
       "      <td>group B</td>\n",
       "      <td>master's degree</td>\n",
       "      <td>standard</td>\n",
       "      <td>none</td>\n",
       "      <td>90</td>\n",
       "      <td>95</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>male</td>\n",
       "      <td>group A</td>\n",
       "      <td>associate's degree</td>\n",
       "      <td>free/reduced</td>\n",
       "      <td>none</td>\n",
       "      <td>47</td>\n",
       "      <td>57</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>male</td>\n",
       "      <td>group C</td>\n",
       "      <td>some college</td>\n",
       "      <td>standard</td>\n",
       "      <td>none</td>\n",
       "      <td>76</td>\n",
       "      <td>78</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender race/ethnicity parental level of education         lunch  \\\n",
       "0  female        group B           bachelor's degree      standard   \n",
       "1  female        group C                some college      standard   \n",
       "2  female        group B             master's degree      standard   \n",
       "3    male        group A          associate's degree  free/reduced   \n",
       "4    male        group C                some college      standard   \n",
       "\n",
       "  test preparation course  math score  reading score  writing score  \n",
       "0                    none          72             72             74  \n",
       "1               completed          69             90             88  \n",
       "2                    none          90             95             93  \n",
       "3                    none          47             57             44  \n",
       "4                    none          76             78             75  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们发现，每个同学都有五个特征：“gender”（性别）、“race/ethnicity”（种族）、“parental level of education”（父母受教育程度）、“lunch”（午餐标准）、“test preparation course”（是否参与考试复习课）。数据集中还给出了每个同学三门考试的成绩。\n",
    "\n",
    "我们再利用**info()**方法对数据做出简单的总结："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 8 columns):\n",
      "gender                         1000 non-null object\n",
      "race/ethnicity                 1000 non-null object\n",
      "parental level of education    1000 non-null object\n",
      "lunch                          1000 non-null object\n",
      "test preparation course        1000 non-null object\n",
      "math score                     1000 non-null int64\n",
      "reading score                  1000 non-null int64\n",
      "writing score                  1000 non-null int64\n",
      "dtypes: int64(3), object(5)\n",
      "memory usage: 62.6+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据集中共有1000个数据，五个特征与三门成绩均有1000个非空值，说明数据集中**没有空值（NA）**，如果有空值，我们需要用**fillna()**来填补空值。具体做法可以参考[Pandas的官方说明](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.fillna.html)或[Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow, 2nd edition](http://shop.oreilly.com/product/0636920142874.do)一书。\n",
    "\n",
    "三门成绩的数据类型均为“int64”，均为数值型数据；五个特征的数据类型均为“object”，因此其有可能为任何python对象，由head()我们可知，五个特征均为文本型数据。\n",
    "\n",
    "如果我们打开csv文件并仔细看，可以发现五个特征均是“类别”特征(categorical attribute)，因为每一列均是将每个学生进行分类，我们可以利用**values_count()**来看每一列究竟是如何分类的，如："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "female    518\n",
       "male      482\n",
       "Name: gender, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"gender\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❗️ 我们拿到数据后发现其特征全为类别特征，因此处理数据十分麻烦。在实际应用中，我们可以和数据管道上一环节的人反馈，令其在以后给数据时，将所有的类别特征合理地转化为数字特征，这样会方便我们的工作。\n",
    "\n",
    "我们可以用**hist()**方法来画出数字型数据的直方图。因为我们只预测数学成绩，我们将数学成绩的直方图画出来："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "data[\"math score\"].hist(bins=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "大多数机器学习算法更容易处理数字型数据，因此我们要想办法将类别特征转化为数字特征。我们有多种方法来做到这点，但是在此之前，我们需要创建测试集。\n",
    "\n",
    "❗️ 为什么我们不在创建测试集前就将类别特征转化为数字特征？在测试时，我们将测试集看作**未来**系统投入使用后输入的数据，鉴于我们无法“预知未来”，我们需要在对数据集做进一步修改前就将测试集分出去，且**在训练和验证过程中，永不使用测试集**。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (4) 创建测试集\n",
    "我们可以用sklearn库的**train_test_split()**函数来创建测试集。利用train_test_split()来创建测试集是根据种子(random_state)\"随机抽样\"的，如果我们的数据集很大（如数十万条数据），可以运用这个函数。但是我们的数据集仅有1000条数据，随机抽样会导致测试集无法代表整体数据。我们接下来便验证这一点：\n",
    "\n",
    "由于我们要预测数学成绩，我们可以将测试集和整体数据的数学成绩大体分布进行对比。通过直方图我们可以看出，大多数的成绩聚集于40-90之间，我们可以用**cut()**将其分成(-∞,40]，(40,50]，(50,60]，(60,70]，(70,80]，(80,90]，(90,100]七个组，并将组名命名为1-7，最后将组名作为新的一列加入至数据集中，列名命名为\"math category\"："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "data[\"math category\"] = pd.cut(data[\"math score\"], bins = [-np.inf, 40, 50, 60, 70, 80, 90, 100], labels = [1, 2, 3, 4, 5, 6, 7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们计算出每组所占的百分比："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    0.270\n",
       "5    0.215\n",
       "3    0.189\n",
       "6    0.126\n",
       "2    0.100\n",
       "7    0.050\n",
       "1    0.050\n",
       "Name: math category, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"math category\"].value_counts()/len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在我们用sklearn库的**train_test_split()**函数来创建测试集，令测试集的大小为整体数据集的20%(test_size=0.2)："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_set, test_set = train_test_split(data, test_size = 0.2, random_state = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们再算出随机抽样的测试集中每组占的百分比："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    0.290\n",
       "3    0.205\n",
       "5    0.170\n",
       "6    0.140\n",
       "2    0.115\n",
       "1    0.045\n",
       "7    0.035\n",
       "Name: math category, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set[\"math category\"].value_counts()/len(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们可以算出相对误差： 1：-20.00%  2：15.00%  3：8.47%  4：7.41%  5：-20.93%  6：11.11%  7：-30.00%\n",
    "\n",
    "可以看出，随机抽样的相对误差很大。如果我们继续下去，最后得到的模型很可能并不适用于现实数据。\n",
    "\n",
    "因此我们需要分层抽样(stratified sampling)，我们使用sklearn的**StratifiedShuffleSplit()**类来根据math category做分成抽样："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "split = StratifiedShuffleSplit(n_splits = 1, test_size = 0.2, random_state = 1)\n",
    "for train_index, test_index in split.split(data, data[\"math category\"]):\n",
    "    strat_train_set = data.loc[train_index]\n",
    "    strat_test_set = data.loc[test_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们再算出分成抽样抽取的测试集中每组占的百分比:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    0.270\n",
       "5    0.215\n",
       "3    0.190\n",
       "6    0.125\n",
       "2    0.100\n",
       "7    0.050\n",
       "1    0.050\n",
       "Name: math category, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strat_test_set[\"math category\"].value_counts()/len(strat_test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们可以算出相对误差：1：0%, 2：0%, 3：5.29%, 4：0%, 5：0%, 6：-8.00%, 7：0%\n",
    "\n",
    "注意此处的0%并不指**一定没有误差**，只是我们按比例算，误差极其小而已。无论如何，我们可以看到，分层抽样的误差较小，因此我们将会把分层抽样出的测试集作为我们的测试集。在此之前，由于我们不想在创建测试集前对数据集进行修改，而math category一列是我们为分测试集而加入的，之后也不需要它，我们**将其删除**。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for set_ in (strat_train_set, strat_test_set):\n",
    "    set_.drop(\"math category\", axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在strat_train_set和strat_test_set是两个不交的集合，二者的并是原数据集。strat_test_set是我们的测试集，在测试前，我们不动测试集。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.为算法准备数据\n",
    "### (1) 数据清洗\n",
    "我们将要对训练集进行数据清洗，为了保留训练集的备份，我们需要复制一个训练集，然后对复制的训练集进行清洗及后续操作。同时，我们只想对五个特征进行数据清洗，我们需要将五个特征和三门成绩**分开**，鉴于我们只预测数学成绩，我们的**标签只是数学成绩**，我们暂时可以抛弃其他两门成绩："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy = strat_train_set[[\"gender\",\"race/ethnicity\",\"parental level of education\",\"lunch\",\"test preparation course\"]]\n",
    "copy_label = strat_train_set[\"math score\"].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) 将类别特征转化为数字特征\n",
    "我们注意到数据的五个特征全是类别特征，没有数字特征，因此我们现在需要将类别特征全部转化为数字特征，然后才能选择算法。我们可以使用sklearn的**ColumnTransformer和OneHotEncoder**："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<800x17 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 4000 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "attributes = list(copy)\n",
    "full_pipeline = ColumnTransformer([(\"cat\",OneHotEncoder(),attributes)])\n",
    "copy_encoded = full_pipeline.fit_transform(copy)\n",
    "copy_encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们将训练集转化为了800行17列的稀疏矩阵(sparse matrix)，我们可以使用对数据套用模型了。在下一篇教程将会包括有关模型与算法的部分。因为下一篇教程是另一个python3文件，我们需要将copy_label，copy_encoded，strat_train_set和strat_test_set存到本地，在下一篇教程中再次读取："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import sparse\n",
    "sparse.save_npz('copy_encoded.npz',copy_encoded)\n",
    "copy_label.to_csv('copy_label.csv',index=False, header=True)\n",
    "strat_train_set.to_csv('strat_train_set.csv', index=False, header=True)\n",
    "strat_test_set.to_csv('strat_test_set.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 参考资料：\n",
    "* “Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow, 2nd edition”  作者：Aurélien Géron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
